{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing Notebook\n",
        "## Privacy, Security, and Compliance of GenAI in LMS\n",
        "\n",
        "**Module:** 7150CEM\n",
        "**Date:** November 2024\n",
        "\n",
        "This notebook performs data cleaning, transformation, and preparation for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "print('Environment ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw dataset\n",
        "df_raw = pd.read_csv('../data_proc/survey_raw_copy.csv')\n",
        "print(f'Loaded: {df_raw.shape[0]:,} rows \u00d7 {df_raw.shape[1]} columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Handle Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze missing data patterns\n",
        "missing_pct = (df_raw.isnull().sum() / len(df_raw)) * 100\n",
        "print('Variables with >20% missing:')\n",
        "print(missing_pct[missing_pct > 20].sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove duplicates\n",
        "df_clean = df_raw.drop_duplicates()\n",
        "print(f'Removed {len(df_raw) - len(df_clean)} duplicates')\n",
        "\n",
        "# Remove rows with excessive missing data (>50% missing)\n",
        "missing_per_row = df_clean.isnull().sum(axis=1) / len(df_clean.columns)\n",
        "df_clean = df_clean[missing_per_row < 0.5]\n",
        "print(f'Remaining rows: {len(df_clean):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Variable Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize Likert scales to 1-5\n",
        "# Q18 series (privacy concerns) already in 1-5 format\n",
        "q18_cols = [col for col in df_clean.columns if col.startswith('Q18')]\n",
        "print(f'Privacy concern variables (Q18): {len(q18_cols)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create Composite Indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Privacy Concern Index (PCI)\n",
        "q18_cols = [col for col in df_clean.columns if col.startswith('Q18') and len(col) == 4]\n",
        "if q18_cols:\n",
        "    df_clean['Privacy_Concern_Index'] = df_clean[q18_cols].mean(axis=1)\n",
        "    print(f'Privacy Concern Index created')\n",
        "    print(f'  Mean: {df_clean[\"Privacy_Concern_Index\"].mean():.2f}')\n",
        "    print(f'  Median: {df_clean[\"Privacy_Concern_Index\"].median():.2f}')\n",
        "    print(f'  Std: {df_clean[\"Privacy_Concern_Index\"].std():.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Protection Awareness Index (DPAI)\n",
        "q19_cols = [col for col in df_clean.columns if col.startswith('Q19')]\n",
        "if q19_cols:\n",
        "    df_clean['Data_Protection_Awareness_Index'] = df_clean[q19_cols].mean(axis=1)\n",
        "    print(f'Data Protection Awareness Index created')\n",
        "    print(f'  Mean: {df_clean[\"Data_Protection_Awareness_Index\"].mean():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Demographic Recoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Age groups\n",
        "if 'Q3' in df_clean.columns:\n",
        "    df_clean['Age'] = pd.to_numeric(df_clean['Q3'], errors='coerce')\n",
        "    df_clean['Age_Group'] = pd.cut(df_clean['Age'], \n",
        "                                     bins=[0, 21, 25, 30, 40, 100],\n",
        "                                     labels=['18-21', '22-25', '26-30', '31-40', '41+'])\n",
        "    print('Age groups created')\n",
        "    print(df_clean['Age_Group'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Data Quality Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for outliers in age\n",
        "if 'Age' in df_clean.columns:\n",
        "    Q1 = df_clean['Age'].quantile(0.25)\n",
        "    Q3 = df_clean['Age'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    outliers = df_clean[(df_clean['Age'] < Q1 - 1.5*IQR) | (df_clean['Age'] > Q3 + 1.5*IQR)]\n",
        "    print(f'Age outliers detected: {len(outliers)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Cleaned Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save cleaned dataset\n",
        "output_file = '../data_proc/survey_clean.csv'\n",
        "df_clean.to_csv(output_file, index=False)\n",
        "print(f'\u2713 Cleaned dataset saved: {output_file}')\n",
        "print(f'  Final shape: {df_clean.shape[0]:,} rows \u00d7 {df_clean.shape[1]} columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Preprocessing Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('='*80)\n",
        "print('PREPROCESSING SUMMARY')\n",
        "print('='*80)\n",
        "print(f'Original rows: {len(df_raw):,}')\n",
        "print(f'Final rows: {len(df_clean):,}')\n",
        "print(f'Rows removed: {len(df_raw) - len(df_clean):,} ({(len(df_raw)-len(df_clean))/len(df_raw)*100:.1f}%)')\n",
        "print(f'\\nComposite indices created:')\n",
        "if 'Privacy_Concern_Index' in df_clean.columns:\n",
        "    print(f'  \u2713 Privacy Concern Index')\n",
        "if 'Data_Protection_Awareness_Index' in df_clean.columns:\n",
        "    print(f'  \u2713 Data Protection Awareness Index')\n",
        "print('\\n\u2713 Data preprocessing complete')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}